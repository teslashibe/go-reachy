# go-reachy ğŸ¤–

A high-performance Go controller for the [Reachy Mini](https://www.pollen-robotics.com/reachy-mini/) robot.

**Run Go code directly ON the robot** â€” no laptop tether required!

## âœ¨ Features

- **Single binary deployment** â€” no Python, no dependencies
- **Cross-compile for ARM64** â€” runs directly on the robot's Raspberry Pi 4
- **Sub-millisecond control loops** â€” real-time performance
- **~8MB binary** â€” vs ~200MB for Python environment
- **Native concurrency** â€” goroutines for parallel operations

## ğŸš€ Quick Start

```bash
# Clone
git clone https://github.com/teslashibe/go-reachy.git
cd go-reachy

# Build
go build ./...

# Run dance demo (replace IP with your robot's)
go run ./cmd/dance
```

## ğŸ¤– Run on the Robot (Standalone)

```bash
# Cross-compile for ARM64
GOOS=linux GOARCH=arm64 go build -o dance-arm64 ./cmd/dance

# Deploy to robot
scp dance-arm64 pollen@reachy-mini.local:~/dance

# SSH and run
ssh pollen@reachy-mini.local "./dance"
```

## ğŸ“ Project Structure

```
go-reachy/
â”œâ”€â”€ cmd/
â”‚   â”œâ”€â”€ eva/             # Eva conversational AI agent
â”‚   â”œâ”€â”€ reachy/          # Main CLI
â”‚   â”œâ”€â”€ poc/             # Proof of concept
â”‚   â””â”€â”€ dance/           # Dance demo â† start here!
â”œâ”€â”€ pkg/
â”‚   â”œâ”€â”€ robot/           # Robot control (HTTP/WebSocket)
â”‚   â”œâ”€â”€ tracking/        # Head tracking (face + audio DOA)
â”‚   â”œâ”€â”€ speech/          # Speech-synced head wobble
â”‚   â”œâ”€â”€ video/           # WebRTC video stream
â”‚   â”œâ”€â”€ tts/             # Text-to-speech (ElevenLabs, OpenAI)
â”‚   â”œâ”€â”€ eva/             # Eva AI tools and personality
â”‚   â”œâ”€â”€ worldmodel/      # Entity tracking and spatial awareness
â”‚   â”œâ”€â”€ memory/          # Persistent memory storage
â”‚   â””â”€â”€ debug/           # Conditional debug logging
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ ARCHITECTURE.md  # System design
â”‚   â”œâ”€â”€ SETUP.md         # Installation guide
â”‚   â””â”€â”€ API.md           # HTTP API reference
â””â”€â”€ go.mod
```

## ğŸ“– Documentation

- [Architecture Overview](docs/ARCHITECTURE.md) â€” system design and data flow
- [Setup Guide](docs/SETUP.md) â€” installation and deployment
- [API Reference](docs/API.md) â€” HTTP endpoints and examples

## ğŸ¯ Roadmap

- [x] HTTP API robot control
- [x] Dance/movement demos
- [x] Cross-compilation for ARM64
- [x] Run directly on robot
- [x] OpenAI Realtime API integration
- [x] Head tracking (face detection + audio DOA)
- [x] Speech-synced head wobble animation
- [x] Breathing animation for idle state
- [x] ElevenLabs TTS streaming
- [x] Microphone audio capture
- [x] Speaker audio playback
- [ ] Systemd service for auto-start
- [ ] Web UI control panel

## ğŸ”§ Robot Configuration

| Setting | Value |
|---------|-------|
| Hostname | `reachy-mini.local` |
| SSH User | `pollen` |
| SSH Password | `root` |
| HTTP API | `http://<IP>:8000` |

## ğŸ“¦ Why Go?

| Metric | Python | Go |
|--------|--------|-----|
| Deployment | venv + 142 packages | Single 8MB binary |
| Control latency | 10-50ms | <1ms |
| Memory | ~200MB | ~10MB |
| Cross-compile | Complex | `GOOS=linux GOARCH=arm64` |

## ğŸ¤ Contributing

Contributions welcome! Please read the [Architecture](docs/ARCHITECTURE.md) doc first.

## ğŸ“„ License

MIT

---

Made with â¤ï¸ for robotics
